{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp pifpafpose_detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detect\n",
    "\n",
    "> Pose Detector class based on Open PifPaf and some pose modification tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#%pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "#%pip install openpifpaf==0.11.5\n",
    "#%pip install opencv-python\n",
    "\n",
    "!wget https://github.com/vita-epfl/openpifpaf-torchhub/releases/download/v0.11.0/shufflenetv2k30w-200510-104256-cif-caf-caf25-o10s-0b5ba06f.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import openpifpaf\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class Detector:\n",
    "    \"\"\"Given a still image (or video frame), finds poses.\n",
    "    \n",
    "    Attributes:  \n",
    "      device: PyTorch computing resource (GPU or CPU)  \n",
    "      net: Pose detection neural network model  \n",
    "      processor: Pose detection image processor  \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        try:\n",
    "            self.device = torch.device('cuda')  # if cuda is available\n",
    "        except:\n",
    "            self.device = torch.device('cpu')\n",
    "        \n",
    "        net_cpu, _ = openpifpaf.network.factory(checkpoint='shufflenetv2k30w-200510-104256-cif-caf-caf25-o10s-0b5ba06f.pkl', download_progress=False)\n",
    "        self.net = net_cpu.to(self.device)\n",
    "\n",
    "        # These could be parameters to __init__()\n",
    "        openpifpaf.decoder.CifSeeds.threshold = 0.5\n",
    "        openpifpaf.decoder.nms.Keypoints.keypoint_threshold = 0.2\n",
    "        openpifpaf.decoder.nms.Keypoints.instance_threshold = 0.2\n",
    "        \n",
    "        self.processor = openpifpaf.decoder.factory_decode(selt.net.head_nets, basenet_stride=self.net.base_net.stride)\n",
    "\n",
    "        self.__preprocess__ = openpifpaf.transforms.Compose([\n",
    "            openpifpaf.transforms.NormalizeAnnotations(),\n",
    "            openpifpaf.transforms.CenterPadTight(16),\n",
    "            openpifpaf.transforms.EVAL_TRANSFORM,])\n",
    "\n",
    "    def __detect_one_or_more_images__(self, batch):\n",
    "        data = openpifpaf.datasets.PilImageList(batch, preprocess=self.__preprocess__)\n",
    "        batch_size = len(batch)\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            data, batch_size=batch_size, pin_memory=True, \n",
    "            collate_fn=openpifpaf.datasets.collate_images_anns_meta)\n",
    "\n",
    "        for images_batch, _, __ in loader:\n",
    "            detections = self.processor.batch(self.net, images_batch, device=self.device)[0]\n",
    "  \n",
    "        return detections\n",
    "\n",
    "    def detect_image(self, image_path):\n",
    "        \"\"\" Applies the pose detection model to a single image file. Returns detections. \"\"\"\n",
    "        pil_image = Image.open(image_path)\n",
    "        detections = self.__detect_one_or_more_images__([pil_image], self.processor)\n",
    "        return detections\n",
    "    \n",
    "    def detect_video(video_file, start_seconds=0.0, end_seconds=0.0, max_frames=0, seconds_to_skip=0.0, images_too=False, write_images=False, folder_name='video_folder'):\n",
    "        \"\"\" Given a video file, extracts video frames as images at `seconds_to_skip` intervals,\n",
    "            from `start_seconds` to `end_seconds`, and runs `__detect_one_or_more_images__()` on each.\n",
    "            Returns a list of frame pose data items, which are dictionaries with the following elements:\n",
    "            { 'frame_id': <the frame's position in this list (not in the entire video, if seconds_to_skip != 0)>, \n",
    "              'time': <the frame's timecode within the excerpt (not within the full video, if start_seconds != 0)>,\n",
    "              'figures': [<OpenPifPaf pose detection objects> for all figures detected in the frame]\n",
    "              <OPTIONAL> 'image': <a PIL image object for the frame>\n",
    "            }\n",
    "            `write_images`, if true, causes the extracted frame images to be written to a folder\n",
    "            specified by `folder_name`, with the naming scheme `image00001.png`\n",
    "        \"\"\"\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_file)\n",
    "\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print('total frames in video:',total_frames)\n",
    "\n",
    "        video_framerate = cap.get(cv2.CAP_PROP_FPS)\n",
    "        print('video FPS:',video_framerate)\n",
    "        frame_duration = 1 / float(video_framerate)\n",
    "\n",
    "        frame_count = 0.0\n",
    "        frames_processed = 0\n",
    "        timecode = 0.0\n",
    "        skip_until = start_seconds\n",
    "\n",
    "        pose_output = []\n",
    "\n",
    "        if write_images:\n",
    "            if not os.path.isdir(folder_name):\n",
    "                os.mkdir(folder_name)\n",
    "            for filename in os.listdir(folder_name):\n",
    "                file_path = os.path.join(folder_name, filename)\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "\n",
    "        while cap.isOpened() and (frame_count < total_frames):\n",
    "            ret_val, im = cap.read()\n",
    "\n",
    "            timecode = frame_count * frame_duration\n",
    "            frame_count += 1\n",
    "\n",
    "            if (end_seconds and timecode > end_seconds) or (max_frames and frames_processed >= max_frames):\n",
    "                return pose_output\n",
    "\n",
    "            if timecode < start_seconds:\n",
    "                continue\n",
    "\n",
    "            if m is None:\n",
    "                # Might want to retry here\n",
    "                # print(\"Missed a frame, continuing...\")\n",
    "                # For now, we'll count a missed frame as a processed frame\n",
    "                continue\n",
    "\n",
    "            if seconds_to_skip and timecode < skip_until:\n",
    "                continue\n",
    "            else:\n",
    "                skip_until += seconds_to_skip\n",
    "\n",
    "            im_height, im_width, im_channels = im.shape\n",
    "\n",
    "            frame_id = int(round(cap.get(1)))\n",
    "\n",
    "            # Image doesn't necessarily come in as RGB(A)!\n",
    "            rgbim = cv2.cvtColor(im, cv2.COLOR_BGR2RGBA)\n",
    "            pil_image = Image.fromarray(rgbim)\n",
    "\n",
    "            detections = self.__detect_one_or_more_images__([pil_image])\n",
    "\n",
    "            print(\"Frame\",frame_count,\"of\",total_frames,round(timecode,2),\"figures\",len(detections))\n",
    "\n",
    "            this_frame_data = {'frame_id': frame_count, 'time': timecode, 'figures': detections} #, 'flipped_figures': flipped_detections, 'zeroified_figures': zeroified_detections}\n",
    "            if images_too:\n",
    "                this_frame_data['image'] = rgbim\n",
    "            if write_images:\n",
    "                pil_image.save(os.path.join(folder_name, 'image' + str(int(frames_processed + 1)).zfill(5) + '.png'), 'PNG')\n",
    "\n",
    "            pose_output.append(this_frame_data)\n",
    "            frames_processed += 1\n",
    "\n",
    "        return pose_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Detector.detect_image)\n",
    "show_doc(Detector.detect_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    teddy = Detector()\n",
    "    detections = teddy.detect_image('sample_data/sample1.png')\n",
    "    print(detections[0])\n",
    "except:\n",
    "    print(\"Unable to instantiate a detector on your system. Do you have PyTorch with CUDA enabled?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
