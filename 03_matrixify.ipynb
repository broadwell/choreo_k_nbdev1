{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp matrixify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# matrixify\n",
    "\n",
    "> Tools to convert detected/corrected poses to matrix representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%pip install --upgrade scikit-bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import lil_matrix\n",
    "import networkx as nx\n",
    "\n",
    "def matrixify_pose(coords_and_confidence):\n",
    "    \"\"\" DISTANCE MATRIX: compute a pose's L1-normed inter-keypoint distance matrix.\n",
    "        To compare any two poses, we can measure the degree of correlation between\n",
    "        their distance matrices via a statistical test, such as the Mantel test.\n",
    "        XXX It's not obvious that normalizing the matrix really makes a difference to\n",
    "        the final correlation comparison, but it doesn't seem to hurt, either...\n",
    "        Note that if the pose representation has 17 keypoints, then each pose instance\n",
    "        can be represented by a condensed distance matrix (or vector) of 136 elements.\n",
    "    \"\"\"\n",
    "    \n",
    "    if coords_and_confidence.shape[0] == 0:\n",
    "            return None\n",
    "    coords = coords_and_confidence[:,:2]\n",
    "    condensed_distance_matrix = normalize(pdist(coords, 'sqeuclidean').reshape(1, -1))[0,:]\n",
    "    return condensed_distance_matrix\n",
    "\n",
    "\n",
    "def get_pose_matrix(frame, figure_index=0, figure_type='flipped_figures'):\n",
    "    if figure_type not in frame or figure_index > len(frame[figure_type])-1 or frame[figure_type][figure_index].data.shape[0] == 0:\n",
    "        return None\n",
    "    coords_and_confidence = frame[figure_type][figure_index].data\n",
    "    return matrixify_pose(coords_and_confidence)\n",
    "\n",
    "\n",
    "def get_laplacian_matrix(frame, normalized=True, show=False, figure_index=0, figure_type='flipped_figures'):\n",
    "    \"\"\" LAPLACIAN: compute the Delaunay triangulation between keypoints, then\n",
    "        use the connections to build an adjacency matrix, which is then converted\n",
    "        to its (normalized) Laplacian matrix (a single matrix that encapsulates the\n",
    "        degree of each node and the connections between the nodes). Then you can\n",
    "        subtract a pose's Laplacian from another's to get a measure of the degree of\n",
    "        similarity or difference between them.\n",
    "    \"\"\"\n",
    "    \n",
    "    if figure_type not in frame or figure_index > len(frame[figure_type])-1 or frame[figure_type][figure_index].data.shape[0] == 0:\n",
    "        return None\n",
    "    \n",
    "    all_points = frame[figure_type][figure_index].data\n",
    "\n",
    "    # For visualization, remove all [x,y,0] (unknown) coordinates.\n",
    "    nonzero = (all_points!=0).all(axis=1)\n",
    "    nz_points = all_points[nonzero]\n",
    "    points = nz_points[:,:2]\n",
    "    total_points = len(points)\n",
    "    try:\n",
    "        tri = Delaunay(points)\n",
    "    except:\n",
    "        # Not sure why this happens -- maybe the points are all in a line or something\n",
    "        print(\"Error computing Delaunay triangulation\")\n",
    "        return None\n",
    "\n",
    "    if show:\n",
    "        plot_delaunay(frame[figure_type][figure_index])\n",
    "\n",
    "    adjacency_matrix = lil_matrix((total_points, total_points), dtype=int)\n",
    "    for i in np.arange(0, np.shape(tri.simplices)[0]):\n",
    "        for j in tri.simplices[i]:\n",
    "            if j < total_points:\n",
    "                adjacency_matrix[j, tri.simplices[i][tri.simplices[i] < total_points]] = 1\n",
    "\n",
    "    adjacency_graph = nx.from_scipy_sparse_matrix(adjacency_matrix)\n",
    "\n",
    "    if normalized:\n",
    "        lm = nx.normalized_laplacian_matrix(adjacency_graph)\n",
    "    else:\n",
    "        lm = nx.laplacian_matrix(adjacency_graph)\n",
    "\n",
    "    return lm\n",
    "\n",
    "\n",
    "def compare_laplacians(p1, p2, figure_index=0, figure_type='flipped_figures', show=False):\n",
    "    lm1 = get_laplacian_matrix(p1, figure_index=figure_index, figure_type=figure_type, show=show).todense()\n",
    "    lm2 = get_laplacian_matrix(p2, figure_index=figure_index, figure_type=figure_type, show=show).todense()\n",
    "    if lm1.shape[0] != lm2.shape[0]:\n",
    "        return None\n",
    "    movement = np.subtract(lm1, lm2)\n",
    "    return 1 - abs(movement.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
