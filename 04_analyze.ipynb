{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyze\n",
    "\n",
    "> Tools for computing movement/pose similarity time series, clustering for single- and multi-dancer videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from openpifpaf.datasets.constants import COCO_KEYPOINTS, COCO_PERSON_SKELETON\n",
    "\n",
    "# May not need all of these here...\n",
    "#import io\n",
    "import numpy as np\n",
    "#import PIL\n",
    "from PIL import Image\n",
    "#import pickle\n",
    "#import matplotlib.pyplot as plt\n",
    "import math\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\n",
    "  action='ignore', module='matplotlib.figure', category=UserWarning,\n",
    "  message=('This figure includes Axes that are not compatible with tight_layout, '\n",
    "           'so results might be incorrect.'))\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def smooth_series(x, window_len=11, window='flat'):\n",
    "    \"\"\" Smooth a time series via a sliding window average\n",
    "        From https://scipy-cookbook.readthedocs.io/items/SignalSmooth.html\n",
    "        Generally used as a helper function to process_time_series() below.\n",
    "    \"\"\"\n",
    "    if x.ndim != 1:\n",
    "        raise(ValueError, \"smooth only accepts 1 dimension arrays.\")\n",
    "\n",
    "    if x.size < window_len:\n",
    "        raise(ValueError, \"Input vector needs to be bigger than window size.\")\n",
    "\n",
    "    if window_len<3:\n",
    "        print(\"WARNING: window length too small for smoothing, returning input data\")\n",
    "        return x\n",
    "\n",
    "    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n",
    "        raise(ValueError, \"Window is one of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\")\n",
    "\n",
    "    s=np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n",
    "    if window == 'flat': #moving average\n",
    "        w=np.ones(window_len,'d')\n",
    "    else:\n",
    "        w=eval('np.'+window+'(window_len)')\n",
    "\n",
    "    y=np.convolve(w/w.sum(),s,mode='valid')\n",
    "\n",
    "    # Move the window 1/2 width back to avoid lag\n",
    "    if window_len % 2 == 0:\n",
    "        return y[int(window_len/2)-1:-(int(window_len/2))]\n",
    "    else:\n",
    "        return y[int(window_len/2):-(int(window_len/2))]\n",
    "\n",
    "\n",
    "def corr_time_series_matrix(pose_data, method='distance'):\n",
    "    \"\"\" Generate a full time-series pose similarity heatmap for all available\n",
    "        poses and frames from the video. This code can use either pose\n",
    "        characterization approach; in practice, the distance matrix-based analyses\n",
    "        take longer to calculate but are more accurate.\n",
    "    \"\"\"\n",
    "    pose_correlations = []\n",
    "    for i, pi in enumerate(pose_data):\n",
    "        print(\"Comparing frame\",i,\"to the rest\")\n",
    "        corr_row = []\n",
    "        if method == 'distance':\n",
    "            mi = get_pose_matrix(pi)\n",
    "        else: # method == 'laplacian'\n",
    "            mi = get_laplacian_matrix(pi)\n",
    "        for j, pj in enumerate(pose_data):\n",
    "            if j < i:\n",
    "                corr_row.append(pose_correlations[j][i])\n",
    "            elif j == i:\n",
    "                corr_row.append(float(1))\n",
    "            else:\n",
    "                if mi is None:\n",
    "                    corr_row.append(float(0))\n",
    "                elif method == 'distance':\n",
    "                    mj = get_pose_matrix(pj)\n",
    "                    if mj is None:\n",
    "                        corr_row.append(float(0))\n",
    "                    else:\n",
    "                        corr_row.append(mantel(mi, mj)[0])\n",
    "                else: # method == 'laplacian'\n",
    "                    mj = get_laplacian_matrix(pj, figure_index=0, figure_type='flipped_figures')\n",
    "                    if mj is None:\n",
    "                        corr_row.append(float(0))\n",
    "                    else:\n",
    "                        corr_row.append(1 - abs(np.subtract(mi.todense(), mj.todense()).sum()))\n",
    "        pose_correlations.append(corr_row)\n",
    "\n",
    "    return pose_correlations\n",
    "\n",
    "\n",
    "def fill_nans_scipy1(padata, pkind='linear'):\n",
    "    \"\"\" Fill in missing values from a time series, after the first non-NAN value\n",
    "        and up to the last non-NAN value. Note that scipy.interpolated.interp1d\n",
    "        provides a lot more options (splines, quadratic, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    aindexes = np.arange(padata.shape[0])\n",
    "    agood_indexes, = np.where(np.isfinite(padata))\n",
    "\n",
    "    first_non_nan_index = agood_indexes[0] \n",
    "    last_non_nan_index = agood_indexes[-1]\n",
    "\n",
    "    f = interp1d(agood_indexes\n",
    "           , padata[agood_indexes]\n",
    "           , bounds_error=False\n",
    "           , copy=False\n",
    "           , fill_value=\"extrapolate\"\n",
    "           , kind=pkind)\n",
    "\n",
    "    interpolated = f(aindexes)\n",
    "    interpolated[0:first_non_nan_index] = np.nan\n",
    "    interpolated[last_non_nan_index+1:] = np.nan\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "def movements_time_series(pose_data, pose_index=-1, method='distance', figure_type='flipped_figures', video_file=None):\n",
    "    \"\"\" Calculate a time series of the differences between each pair of poses in a\n",
    "        sequence. This works with a single figure (pose_index=0) or all the figures\n",
    "        in the video (pose_index=-1). It can be run on its own, but typically this is\n",
    "        a helper function for process_movement_series() (below).\n",
    "    \"\"\"\n",
    "    \n",
    "    per_frame_movements = []\n",
    "    frame_timecodes = []\n",
    "\n",
    "    pose_indices = []\n",
    "\n",
    "    max_figures, total_time, total_figures = count_figures_and_time(pose_data, figure_type)\n",
    "\n",
    "    threshold = .7\n",
    "\n",
    "    #print(\"FIGURES PER FRAME IN TIME SERIES:\",max_figures)\n",
    "\n",
    "    # Typically the pose index is only specified if you know there's only one dancer\n",
    "    # (in which case it's always 0)\n",
    "    if pose_index != -1:\n",
    "        max_figures = 1\n",
    "\n",
    "    for f, frame in enumerate(pose_data):\n",
    "        frame_movements = []\n",
    "        frame_timecodes.append(frame['time'])\n",
    "        if f < len(pose_data)-1:\n",
    "            for p in range(max_figures):\n",
    "                this_motion = np.nan\n",
    "                movers = np.array([])\n",
    "                # figure p must be available for both f and f-1\n",
    "                # NOTE check p < len(pose_data[f][figure_type]) in case the data for that frame has been\n",
    "                # truncated to [] (for example if extraneous data from the end of the video has been removed)\n",
    "                if p < len(pose_data[f-1][figure_type]) and p < len(pose_data[f][figure_type]) and pose_data[f-1][figure_type][p].data.shape[0] != 0 and pose_data[f][figure_type][p].data.shape[0] != 0:\n",
    "                    p1_conf = sum([c[2] for c in pose_data[f-1][figure_type][p].data]) / float(len(pose_data[f-1][figure_type][p].data))\n",
    "                    p2_conf = sum([c[2] for c in pose_data[f][figure_type][p].data]) / float(len(pose_data[f][figure_type][p].data))\n",
    "                    # XXX USE A BETTER CRITERION FOR SKIPPING POSES IF CONFIDENCE IS LOW\n",
    "                    if p1_conf > threshold and p2_conf > threshold:\n",
    "                        if method == 'distance':\n",
    "                            plot_type = 'distance'\n",
    "                            dmatrix1 = squareform(get_pose_matrix(pose_data[f-1], p, figure_type))\n",
    "                            dmatrix2 = squareform(get_pose_matrix(pose_data[f], p, figure_type))\n",
    "                            diffmatrix = np.absolute(dmatrix1 - dmatrix2)\n",
    "                            movers = diffmatrix.sum(axis=1)\n",
    "                            this_motion = movers.sum(axis=0) # For debugging\n",
    "                        else:\n",
    "                            plot_type = 'delaunay'\n",
    "                            # Per-keypoint movements are not useful for Laplacian comparisons\n",
    "                            similarity = compare_laplacians(pose_data[f-1], pose_data[f], p, figure_type)\n",
    "                            # Can we get meaningful movement values if laplacians are of different sizes?\n",
    "                            if similarity is not None:\n",
    "                                movers = np.array([1 - similarity])\n",
    "                \n",
    "                frame_movements.append(movers)    \n",
    "        \n",
    "        per_frame_movements.append(frame_movements)\n",
    "\n",
    "    return [per_frame_movements, frame_timecodes, max_figures]\n",
    "\n",
    "\n",
    "def process_movement_series(pose_data, pose_index=-1, figure_type='flipped_figures', video_file=None, method='distance', interpolate=True, viz=True):\n",
    "    \"\"\" Smooth, summarize, visualize movement data for one or more figures across a\n",
    "        time series.\n",
    "        Also visualize aggregate movement data for each keypoint, if distance matrix\n",
    "        method is used.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"GETTING MOVEMENT TIME SERIES\")\n",
    "    per_frame_results, frame_timecodes, max_figures = movements_time_series(pose_data, pose_index, method, figure_type, video_file)\n",
    "\n",
    "    print(\"CALCULATING CHARACTERISTICS OF TIME SERIES\")\n",
    "\n",
    "    window_length = 5\n",
    "    if video_file is not None:\n",
    "        fps, total_frames = get_video_stats(video_file)\n",
    "        window_length = max(window_length, int(round(fps/2.0)))\n",
    "\n",
    "    movers = [] # To get the aggregate avg movement of each keypoint (not for Laplacian)\n",
    "    movement_series = []\n",
    "    frame_times = []\n",
    "\n",
    "    smoothed_movement_series = []\n",
    "\n",
    "    for j in range(max_figures):\n",
    "        movement_series.append([])  \n",
    "        smoothed_movement_series.append([])\n",
    "\n",
    "    per_frame_movements = []\n",
    "    \n",
    "    for f, frame in enumerate(per_frame_results):\n",
    "        frame_movements = np.zeros(TOTAL_COORDS)\n",
    "        frame_times.append(frame_timecodes[f])\n",
    "        for j in range(max_figures):\n",
    "            if j >= len(frame) or frame[j].shape[0] == 0:\n",
    "                #print(\"POSE\",j,\"HAS NO MOVEMENT DATA\")\n",
    "                movement_series[j].append(np.nan)\n",
    "            elif method == 'distance':\n",
    "                frame_movements = np.add(frame_movements, frame[j])\n",
    "                movement_series[j].append(sum(frame[j]))\n",
    "                movers.append(np.array(frame[j]))\n",
    "            else: # method == 'laplacian'\n",
    "                movement_series[j].append(frame[j][0])\n",
    "            movers.append(frame[j])\n",
    "        per_frame_movements.append(frame_movements)\n",
    "\n",
    "    figure_time_series = np.array(movers)\n",
    "\n",
    "    # Not sure if there's a meaningful way to aggregate the per-keypoint data\n",
    "    # for the graph Laplacian approach (e.g., to be able to quantify how much\n",
    "    # each keypoint moved during the video).\n",
    "    if method == 'distance':\n",
    "        movement_means = np.nanmean(figure_time_series, axis=0)\n",
    "        movement_stdevs = np.nanstd(figure_time_series, axis=0)\n",
    "\n",
    "    # Window length is half of fps (or ~5, whichever is larger)\n",
    "    for j in range(max_figures):\n",
    "        if interpolate:\n",
    "            if np.isnan(np.nanmax(movement_series[j])):\n",
    "                #print(\"Movement series is all nans, skipping\")\n",
    "                continue\n",
    "            smoothed_movement_series[j] = smooth_series(fill_nans_scipy1(np.asarray(movement_series[j]), pkind='linear'),window_length).tolist()\n",
    "        else:\n",
    "            smoothed_movement_series[j] = smooth_series(np.array(movement_series[j]),window_length).tolist()\n",
    "\n",
    "    if viz:\n",
    "        print(\"VISUALIZING TIME SERIES CHARACTERISTICS\")\n",
    "    \n",
    "        if method == 'distance':\n",
    "            plt.figure()\n",
    "            plt.xticks(np.arange(TOTAL_COORDS))\n",
    "\n",
    "            plt.bar(np.arange(TOTAL_COORDS), movement_means)# yerr=movement_stdevs)\n",
    "\n",
    "        fig = plt.figure(figsize=(12,6), constrained_layout=True)\n",
    "        fig.dpi=100\n",
    "\n",
    "        for j in range(len(smoothed_movement_series)):\n",
    "            if (len(smoothed_movement_series[j]) > 0) and not np.isnan(np.nanmax(smoothed_movement_series[j])):\n",
    "                plt.plot(frame_times,smoothed_movement_series[j]) #,color)\n",
    "        plt.show()\n",
    "\n",
    "    if method == 'distance':\n",
    "        return [smoothed_movement_series, frame_times, per_frame_movements, movement_means, movement_stdevs]\n",
    "    else:\n",
    "        return [smoothed_movement_series, frame_times]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
