# AUTOGENERATED! DO NOT EDIT! File to edit: 01_modify.ipynb (unless otherwise specified).

__all__ = ['get_figure_coords', 'flip_detections', 'zeroify_detections', 'get_bbox', 'get_bbox_area', 'in_bbox_check',
           'get_intersect', 'get_union', 'shift_figure', 'average_coords', 'count_figures_and_time',
           'nose_btwn_eyes_ears_shoulders', 'left_eye_btwn_nose_shoulder', 'right_eye_btwn_nose_shoulder',
           'left_ear_btwn_eye_shoulder', 'right_ear_btwn_eye_shoulder', 'left_elbow_btwn_shoulder_wrist',
           'right_elbow_btwn_shoulder_wrist', 'left_hip_btwn_shoulder_knee_ankle', 'right_hip_btwn_shoulder_knee_ankle',
           'left_ankle_from_knee', 'right_ankle_from_knee', 'correct_pose', 'add_flipped_zeroified_figures',
           'interpolate_missing_coords', 'output_alphapose_json', 'add_poseflow_figures', 'TOTAL_COORDS', 'D_THRESH',
           'coco_points', 'coco_pts_short']

# Cell
from openpifpaf.datasets.constants import COCO_KEYPOINTS, COCO_PERSON_SKELETON

# May not need all of these here...
#import io
import numpy as np
#import PIL
from PIL import Image
#import pickle
#import matplotlib.pyplot as plt
import math
import cv2
import os

import warnings
warnings.filterwarnings(
  action='ignore', module='matplotlib.figure', category=UserWarning,
  message=('This figure includes Axes that are not compatible with tight_layout, '
           'so results might be incorrect.'))

TOTAL_COORDS = 17
D_THRESH = 0.01

coco_points = {
    0: 'nose',
    1: 'left_eye',
    2: 'right_eye',
    3: 'left_ear',
    4: 'right_ear',
    5: 'left_shoulder',
    6: 'right_shoulder',
    7: 'left_elbow',
    8: 'right_elbow',
    9: 'left_wrist',
    10: 'right_wrist',
    11: 'left_hip',
    12: 'right_hip',
    13: 'left_knee',
    14: 'right_knee',
    15: 'left_ankle',
    16: 'right_ankle'
}

coco_pts_short = {
    0: 'nose',
    1: 'l_eye',
    2: 'r_eye',
    3: 'l_ear',
    4: 'r_ear',
    5: 'l_shldr',
    6: 'r_shldr',
    7: 'l_elbow',
    8: 'r_elbow',
    9: 'l_wrist',
    10: 'r_wrist',
    11: 'l_hip',
    12: 'r_hip',
    13: 'l_knee',
    14: 'r_knee',
    15: 'l_ankle',
    16: 'r_ankle'
}


def get_figure_coords(coords_and_confidence, margin=0):

    xmin = None
    ymin = None
    xmax = None
    ymax = None

    for coord in coords_and_confidence:
        if coord[2] == 0: # and coord[0] == 0 and coord[1] == 0
            continue
        if xmin is None:
            xmin = coord[0]
        if ymin is None:
            ymin = coord[1]
        if xmax is None:
            xmax = coord[0]
        if ymax is None:
            ymax = coord[1]
    xmin = min(xmin, coord[0])
    ymin = min(ymin, coord[1])
    xmax = max(xmax, coord[0])
    ymax = max(ymax, coord[1])

    marg = 0

    if margin != 0:
        width = xmax - xmin
        height = ymax - ymin
        area = width * height
        x_area = area + area * margin
        marg = int(round(math.sqrt(x_area) * margin))

        xmax = xmax + marg
        xmin = xmin - marg
        ymax = ymax + marg
        ymin = ymin - marg

    xmed = (xmax + xmin) / 2
    ymed = (ymax + ymin) / 2

    return [xmin, ymin, xmax, ymax, xmed, ymed, marg]


def flip_detections(input_detections, flip_y=True, rectify_x=False):
    """ PIL puts the 0,0 origin for images at top left, but the
        distance matrix calculations expect it to be at the bottom left.
        PifPaf wants PIL image input, so the fix for now
        is to flip the coordinates at this point in the pipeline.
        This function flips all detected poses in a single frame.
        If the rectify_x flag is set, this function can also count
        how many coords are on the left or right side of the pose,
        and mirror the coordinates horizontally so that the most
        coords are always on stage right (viewer's left).
    """
    detections = copy.deepcopy(input_detections)

    for detection in detections:

        coords_and_confidence = detection.data

        if coords_and_confidence.shape[0] == 0:
            continue

        xmin, ymin, xmax, ymax, xmed, ymed, marg = get_figure_coords(coords_and_confidence)

        n_rows = coords_and_confidence.shape[0]

        new_cc = np.copy(coords_and_confidence)

        coords_stage_left = 0
        coords_stage_right = 0
        flip_x=False

        if rectify_x:
            #print("XMED IS",xmed)
            for i in range(0,n_rows):
                xval = coords_and_confidence[i,0]
                yval = coords_and_confidence[i,1]
                conf = coords_and_confidence[i,2]
                if xval == 0 and yval == 0 and conf == 0:
                    continue
                if xval > xmed:
                    coords_stage_left += 1
                else:
                    coords_stage_right += 1
                #print("COORDS STAGE LEFT",coords_stage_left,"COORDS STAGE RIGHT",coords_stage_right)
                if coords_stage_left > coords_stage_right:
                    flip_x = True

        for i in range(0,n_rows):
            xval = coords_and_confidence[i,0]
            yval = coords_and_confidence[i,1]
            conf = coords_and_confidence[i,2]
            if xval == 0 and yval == 0 and conf == 0:
                continue
            if flip_y:
                if yval >= ymed:
                    ydiff = yval - ymed
                    newy = ymed - ydiff
                    new_cc[i,1] = newy
                else:
                    ydiff = ymed - yval
                    newy = ymed + ydiff
                    new_cc[i,1] = newy
            if flip_x:
                if xval > xmed:
                    xdiff = xval - xmed
                    newx = xmed - xdiff
                    new_cc[i,0] = newx
                else:
                    xdiff = xmed - xval
                    newx = xmed + xdiff
                    new_cc[i,0] = newx

        detection.data = new_cc

    return detections


def zeroify_detections(input_detections, width=None, height=None):
    """ Modifies a figure's coordinates so that the corner of its bounding
        box is at 0,0. This is mostly for visualization with PIL images,
        (note that PIL puts y=0 at the top).
        The modifications are done for all figures in a single frame.
    """
    detections = copy.deepcopy(input_detections)

    for detection in detections:

        coords_and_confidence = detection.data

        if coords_and_confidence.shape[0] == 0:
            continue

        xmin, ymin, xmax, ymax, xmed, ymed, marg = get_figure_coords(coords_and_confidence)

        if width is not None and height is not None:
            dx = (width - (xmax - xmin)) / 2
            dy = (height - (ymax - ymin)) / 2

            if dx > 0:
                xmin = xmin - dx
                xmax = xmax + dx
            if dy > 0:
                ymin = ymin - dy
                ymax = ymax + dy

        n_rows = coords_and_confidence.shape[0]

        new_cc = np.copy(coords_and_confidence)

        for i in range(0,n_rows):
            xval = coords_and_confidence[i,0]
            yval = coords_and_confidence[i,1]
            conf = coords_and_confidence[i,2]
            if xval == 0 and yval == 0 and conf == 0:
                continue
            new_cc[i,0] = xval - xmin
            new_cc[i,1] = yval - ymin

        detection.data = new_cc

    return detections


def get_bbox(pose_coords, move_to_origin=False, margin=0, width=None, height=None):
    xmin, ymin, xmax, ymax, xmed, ymed, marg = get_figure_coords(pose_coords, margin)

    if width is not None and height is not None:
        dx = (width - (xmax - xmin)) / 2
        dy = (height - (ymax - ymin)) / 2

        if dx > 0:
            xmin = xmin - dx
            xmax = xmax + dx
        if dy > 0:
            ymin = ymin - dy
            ymax = ymax + dy

    if move_to_origin:
        return {'xmax': xmax - xmin, 'xmin': 0, 'ymax': ymax - ymin , 'ymin': 0, 'marg': marg}
    else:
        return {'xmax': xmax, 'xmin': xmin, 'ymax': ymax, 'ymin': ymin, 'marg': marg}



def get_bbox_area(bbox):
    width = bbox['xmax'] - bbox['xmin']
    height = bbox['ymax'] - bbox['ymin']
    return width * height



def in_bbox_check(coord, bbox, margin=.5):
    # The margin should be calculated based on the smallest dimension of the pose
    width = bbox['xmax'] - bbox['xmin']
    height = bbox['ymax'] - bbox['ymin']
    mval = min(width,height) * margin

    if coord[0] > (bbox['xmax'] + mval) or coord[0] < (bbox['xmin'] - mval) or coord[1] > (bbox['ymax'] + mval) or coord[1] < (bbox['ymin'] - mval):
        expanded_bbox = [bbox['xmin'] - mval, bbox['ymin'] - mval, bbox['xmax'] + mval, bbox['ymax'] + mval]
        return False
    else:
        return True


# Get the minimal bounding box of the overlap between two bounding boxes
def get_intersect(a, b):
    minxmax = min(a['xmax'], b['xmax'])
    maxxmin = max(a['xmin'], b['xmin'])
    minymax = min(a['ymax'], b['ymax'])
    maxymin = max(a['ymin'], b['ymin'])
    dx = min(a['xmax'], b['xmax']) - max(a['xmin'], b['xmin'])
    dy = min(a['ymax'], b['ymax']) - max(a['ymin'], b['ymin'])
    if (dx>=0) and (dy>=0):
        return [dx*dy, {'xmin': maxxmin, 'ymin': maxymin, 'xmax': minxmax, 'ymax': minymax}]
    return None


# Get the maximal bounding box around two bounding boxes, if they overlap
def get_union(a, b):
    maxxmax = max(a['xmax'], b['xmax'])
    minxmin = min(a['xmin'], b['xmin'])
    maxymax = max(a['ymax'], b['ymax'])
    minymin = min(a['ymin'], b['ymin'])
    dx = min(a['xmax'], b['xmax']) - max(a['xmin'], b['xmin'])
    dy = min(a['ymax'], b['ymax']) - max(a['ymin'], b['ymin'])
    mx = maxxmax - minxmin
    my = maxymax - minymin
    # Return None if there's no overlap
    if (dx>=0) and (dy>=0):
        return [mx*my, {'xmin': minxmin, 'ymin': minymin, 'xmax': maxxmax, 'ymax': maxymax}]
    return None



def shift_figure(coords_and_confidence, dx, dy):

    if coords_and_confidence.shape[0] == 0:
        return coords_and_confidence

    new_cc = np.copy(coords_and_confidence)
    n_rows = coords_and_confidence.shape[0]

    for i in range(0,n_rows):
        xval = coords_and_confidence[i,0]
        yval = coords_and_confidence[i,1]
        conf = coords_and_confidence[i,2]
        if xval == 0 and yval == 0 and conf == 0:
            continue
        new_cc[i,0] = xval + dx
        new_cc[i,1] = yval + dy
        new_cc[i,2] = conf

    return new_cc


def average_coords(coord1, coord2):
    return np.array([(coord1[0] + coord2[0])/2, (coord1[1] + coord2[1])/2, (coord1[2] + coord2[2])/2])


def count_figures_and_time(input_frames):
    # Determine the maximum number of figures in a single frame of a series,
    # the total number of figures (not used), and the last timecode
    total_figures=0
    max_figures=0
    total_time=0.0
    for i, frame_info in enumerate(input_frames):
        total_figures += len(frame_info['figures'])
        max_figures = max(max_figures, len(frame_info['figures']))
        total_time = max(total_time, frame_info['time'])

    return [max_figures, total_time, total_figures]


def nose_btwn_eyes_ears_shoulders(coords, missing_coords):
    # Nose between eyes
    if 0 in missing_coords and 1 not in missing_coords and 2 not in missing_coords:
        coords[0] =  average_coords(coords[1], coords[2])
        missing_coords.remove(0)
    # Nose between ears, interpolate eyes as well
    elif 0 in missing_coords and 3 not in missing_coords and 4 not in missing_coords:
        coords[0] = average_coords(coords[3], coords[4])
        missing_coords.remove(0)
        coords, missing_coords = left_eye_btwn_nose_shoulder(coords, missing_coords)
        coords, missing_coords = right_eye_btwn_nose_shoulder(coords, missing_coords)
    # Nose between shoulders, interpolate eyes and ears as well
    elif 0 in missing_coords and 5 not in missing_coords and 6 not in missing_coords:
        coords[0] = average_coords(coords[5], coords[6])
        missing_coords.remove(0)
        coords, missing_coords = left_eye_btwn_nose_shoulder(coords, missing_coords)
        coords, missing_coords = right_eye_btwn_nose_shoulder(coords, missing_coords)
        coords, missing_coords = left_ear_btwn_eye_shoulder(coords, missing_coords)
        coords, missing_coords = right_ear_btwn_eye_shoulder(coords, missing_coords)
    return [coords, missing_coords]

def left_eye_btwn_nose_shoulder(coords, missing_coords):
    if 1 in missing_coords and 0 not in missing_coords and 5 not in missing_coords:
        coords[1] = average_coords(coords[0], coords[5])
        missing_coords.remove(1)
    return [coords, missing_coords]

def right_eye_btwn_nose_shoulder(coords, missing_coords):
    if 2 in missing_coords and 0 not in missing_coords and 6 not in missing_coords:
        coords[2] = average_coords(coords[0], coords[6])
        missing_coords.remove(2)
    return [coords, missing_coords]

def left_ear_btwn_eye_shoulder(coords, missing_coords):
    if 3 in missing_coords and 1 not in missing_coords and 5 not in missing_coords:
        coords[3] = average_coords(coords[1], coords[5])
        missing_coords.remove(3)
    return [coords, missing_coords]

def right_ear_btwn_eye_shoulder(coords, missing_coords):
    if 4 in missing_coords and 2 not in missing_coords and 6 not in missing_coords:
        coords[4] = average_coords(coords[2], coords[6])
        missing_coords.remove(4)
    return [coords, missing_coords]

def left_elbow_btwn_shoulder_wrist(coords, missing_coords):
    if 7 in missing_coords and 5 not in missing_coords and 9 not in missing_coords:
        coords[7] = average_coords(coords[5], coords[9])
        missing_coords.remove(7)
    return [coords, missing_coords]

def right_elbow_btwn_shoulder_wrist(coords, missing_coords):
    if 8 in missing_coords and 6 not in missing_coords and 10 not in missing_coords:
        coords[8] = average_coords(coords[6], coords[10])
        missing_coords.remove(8)
    return [coords, missing_coords]

def left_hip_btwn_shoulder_knee_ankle(coords, missing_coords):
    if 11 in missing_coords and 5 not in missing_coords and 13 not in missing_coords:
        coords[11] = average_coords(coords[5], coords[13])
        missing_coords.remove(11)
        return [coords, missing_coords]
    elif 11 in missing_coords and 5 not in missing_coords and 15 not in missing_coords:
        coords[11] = average_coords(coords[5], coords[15])
        missing_coords.remove(11)
        return [coords, missing_coords]

def right_hip_btwn_shoulder_knee_ankle(coords, missing_coords):
    if 12 in missing_coords and 6 not in missing_coords and 14 not in missing_coords:
        coords[12] = average_coords(coords[6], coords[14])
        missing_coords.remove(12)
        return [coords, missing_coords]
    elif 12 in missing_coords and 6 not in missing_coords and 16 not in missing_coords:
        coords[12] = average_coords(coords[6], coords[16])
        missing_coords.remove(12)
        return [coords, missing_coords]

def left_ankle_from_knee(coords, missing_coords):
    if 15 in missing_coords and 11 not in missing_coords and 13 not in missing_coords:
        hipdiff = [coords[11][0] - coords[13][0], coords[11][1] - coords[13][1]]
        coords[15] = np.array([coords[13][0] - hipdiff[0], coords[13][1] - hipdiff[1], D_THRESH])
        missing_coords.remove(15)
    return [coords, missing_coords]

def right_ankle_from_knee(coords, missing_coords):
    if 16 in missing_coords and 12 not in missing_coords and 14 not in missing_coords:
        hipdiff = [coords[12][0] - coords[14][0], coords[12][1] - coords[14][1]]
        coords[16] = np.array([coords[14][0] - hipdiff[0], coords[14][1] - hipdiff[1], D_THRESH])
        missing_coords.remove(16)
    return [coords, missing_coords]


# Simple pose correction rules (duh)
def correct_pose(input_coords):
    coords = {}
    weird_coords = []
    for c, coord in enumerate(input_coords):
        #if coord[0] == 0 and coord[1] == 0 and coord[2] <= .01:
        if coord[2] <= D_THRESH:
            weird_coords.append(c)
        coords[c] = np.array([coord[0], coord[1], coord[2]])
    if len(weird_coords) == 0:
        #print("NO COORDS TO CORRECT IN correct_pose")
        return {}
    missing_coords = weird_coords.copy()
    for c in sorted(weird_coords):
        coord = coords[c]

        # Find the location of the nose at all costs (between eyes, ears, or shoulders)
        coords, missing_coords = nose_btwn_eyes_ears_shoulders(coords, missing_coords)

        # Put the left eye between the nose and the left shoulder (better than the alternative)
        coords, missing_coords = left_eye_btwn_nose_shoulder(coords, missing_coords)

        # Put the right eye between the nose and the right shoulder (better than the alternative)
        coords, missing_coords = right_eye_btwn_nose_shoulder(coords, missing_coords)

        # Put the left ear between the left eye and the left shoulder (better than the alternative)
        coords, missing_coords = left_ear_btwn_eye_shoulder(coords, missing_coords)
        # Put the right ear between the right eye and the right shoulder (better than the alternative)
        coords, missing_coords = right_ear_btwn_eye_shoulder(coords, missing_coords)
        # Try to put the left shoulder between ear and wrist???
        # Try to put the right shoulder btween ear and wrist???

        # Put the left elbow between the left shoulder and the left wrist (better than the alternative)
        coords, missing_coords = left_elbow_btwn_shoulder_wrist(coords, missing_coords)
        # Put the right elbow between the right shoulder and the right wrist (better than the alternative)
        coords, missing_coords = right_elbow_btwn_shoulder_wrist(coords, missing_coords)

        # If wrists are missing, better to let them default to the middle of the pose than extrapolating
        # from shoulder-to-elbow segments (probably?) OR XXX put the wrists on top of the elbows?

        # Put the left hip between the left shoulder and the left knee (better than the alternative)
        # Or between the left shoulder and left ankle
        coords, missing_coords = left_hip_btwn_shoulder_knee_ankle(coords, missing_coords)

        # Put the right hip between the right shoulder and the right knee (better than the alternative)
        coords, missing_coords = right_hip_btwn_shoulder_knee_ankle(coords, missing_coords)

        # If left ankle is missing, extrapolate from left hip-to-knee segments
        coords, missing_coords = left_ankle_from_knee(coords, missing_coords)

        # If right ankle is missing, extrapolate from right hip-to-knee segments
        coords, missing_coords = right_ankle_from_knee(coords, missing_coords)

    corrected_coords = {}
    for w in weird_coords:
        if w not in missing_coords:
            corrected_coords[w] = coords[w]

    return corrected_coords


def add_flipped_zeroified_figures(input_frames, add_flipped=True, add_zerofied=True):
    output_frames = copy.deepcopy(input_frames)

    for i, frame_info in enumerate(input_frames):
        if add_flipped:
            flipped_detections = flip_detections(frame_info['figures'])
            output_frames[i]['flipped_figures'] = flipped_detections
        if add_zeroified:
            zeroified_detections = zeroify_detections(frame_info['figures'])
            output_frames[i]['zeroified_figures'] = zeroified_detections

    return output_frames


def interpolate_missing_coords(input_frames, threshold=.5, flip_figures=False, check_bbox=False, all_visible=True, overlap_threshold=.7, video_file=None):
    # Most matrix comparison methods do not allow for empty rows/colums.
    # Given a series of poses, fill in each missing point by taking the average of
    # its last and next known pcosition (or one of them, if the other is not known).
    # Also do this for points with confidence levels < some threshold (50%).
    # If no coordinates are available, use the x,y centroid of the poses for that figure (?)
    # Note that pose data is grouped by frame and then by figure within each frame.

    frame_series = copy.deepcopy(input_frames)

    max_figures, total_time, total_figures = count_figures_and_time(frame_series, 'figures')
    print("MAX FIGURES",max_figures,"TOTAL FIGURES",total_figures)

    frame_search_limit = int(round(float(len(frame_series)) / total_time))
    print(len(frame_series),"FRAMES OVER",total_time,"SECONDS","FPS ROUNDED TO",frame_search_limit)

    for i, frame_info in enumerate(input_frames):

        if 'figures' not in frame_info:
            print("NO FIGURES IN",'figures',"FOR FRAME",i)
            frame_series[i]['figures'] = []
            continue
        for f in range(len(frame_info['figures'])):
            if frame_info['figures'][f].data.shape[0] == 0:
                frame_series[i]['figures'][f].data = np.array([])
                continue

            new_coords = np.copy(frame_info['figures'][f].data)
            if new_coords.shape[0] != TOTAL_COORDS:
                print("TRUNCATED FIGURE IN FRAME",i,"FIGURE",f,"NUMBER OF COORDS",new_coords.shape[0])

            bbox = get_bbox(frame_info['figures'][f].data)

            # Maybe put this in a function?
            missing_coords = 0
            confidence_values = []
            for j in range(0,TOTAL_COORDS):
                coord = new_coords[j]
                confidence_values.append(coord[2])
                # Count a coordinate as missing if x,y is 0,0 or if the score is 0
                if coord[2] == 0:
                    missing_coords += 1
            figure_confidence = float(sum(confidence_values)) / float(len(confidence_values))
            if (figure_confidence < threshold) or (missing_coords > TOTAL_COORDS / 2):
                print("FRAME",i,"FIGURE",f,"CONFIDENCE",figure_confidence,"MISSING",missing_coords,"COORDS, REMOVING")

                frame_series[i]['figures'][f].data = np.array([])
                continue

            # XXX Update these as the previous frames are updated? Or just use the original values?
            # If they're updated then there's no need to precompute the paddded bounding boxes above.
            combined_bbox = None
            p_bbox = None
            n_bbox = None
            if i > 0 and 'figures' in frame_series[i-1] and frame_series[i-1]['figures'][f].data.shape[0] != 0:
                p_bbox = get_bbox(frame_series[i-1]['figures'][f].data, margin=.25)
                combined_bbox = p_bbox

            if i < len(frame_series)-1 and 'figures' in frame_series[i+1] and frame_series[i+1]['figures'][f].data.shape[0] != 0:
                n_bbox = get_bbox(frame_series[i+1]['figures'][f].data, margin=.25)
                combined_bbox = n_bbox

            if p_bbox is not None and n_bbox is not None:
                combined_data = get_union(p_bbox, n_bbox)
                if combined_data is None:
                    combined_bbox = bbox
                    combined_area = 0
                else:
                    combined_area, combined_bbox = combined_data

            # XXX Do this for the entire pose once, or after each coordinate is checked/upated?
            for j in range(0,TOTAL_COORDS):
                coord = new_coords[j]
                this_coord = None
                # If the score is 0, it may be an occluded point that could be used
                if coord[2] > threshold and combined_bbox is not None and in_bbox_check(coord, combined_bbox):
                    continue
                else:
                    if all_visible and coord[2] == 0:
                        coord = np.array([coord[0], coord[1], D_THRESH])
                previous_bbox = None
                next_bbox = None
                previous_coord = None
                next_coord = None
                try_extrapolated_position = False
                for p in range(i-1, max(-1,i-frame_search_limit-1), -1):
                    # Figures can appear and disappear from frame to frame
                    if 'figures' in input_frames[p] and f < len(input_frames[p]['figures']) and input_frames[p]['figures'][f].data.shape[0] != 0 and input_frames[p]['figures'][f].data[j][2] > coord[2]:
                        previous_coord = input_frames[p]['figures'][f].data[j]
                        previous_bbox = get_bbox(input_frames[p]['figures'][f].data)
                        break
                for n in range(i, min(i+frame_search_limit+1, len(input_frames))):
                    # Figures can appear and disappear from frame to frame
                    if 'figures' in input_frames[n] and f < len(input_frames[n]['figures']) and input_frames[n]['figures'][f].data.shape[0] != 0 and input_frames[n]['figures'][f].data[j][2] > coord[2]:
                        next_coord = input_frames[n]['figures'][f].data[j]
                        next_bbox = get_bbox(input_frames[n]['figures'][f].data)
                        break
                if previous_coord is not None and next_coord is not None:
                    this_coord = average_coords(previous_coord, next_coord)
                elif previous_coord is not None and next_coord is None:
                    this_coord = previous_coord
                    this_coord[2] += .01
                elif previous_coord is None and next_coord is not None:
                    this_coord = next_coord
                    this_coord[2] += .01

                if this_coord is None or combined_bbox is None or (not in_bbox_check(this_coord, combined_bbox)):
                    # Try to extrapolate the missing coord from present coords
                    corrected_coords = correct_pose(new_coords)
                    if j in corrected_coords and (corrected_coords[j][2] > coord[2] or (coord[0] == 0 and coord[1] == 0)):
                        this_coord = corrected_coords[j]
                        this_coord[2] = max(D_THRESH, this_coord[2])
                        try_extrapolated_position = True
                    elif coord[2] - D_THRESH <= D_THRESH:
                        this_coord = np.array([(bbox['xmax'] + bbox['xmin'])/2, (bbox['ymax'] + bbox['ymin'])/2, D_THRESH])
                    else:
                        continue

                if this_coord is not None:
                    if (not check_bbox) or (previous_bbox is None and next_bbox is None):
                        new_coords[j] = this_coord
                    else:
                        prev_next_overlap = None
                        prev_this_overlap = None
                        this_next_overlap = None
                        # Check if the previous and next bounding boxes overlap more with each other than
                        # either one does with the current frame. If so, the current frame's bounding box
                        # is probably an anomaly, and the intersection (or union?) of the previous and next
                        # bounding boxes should be used in the check, rather than the current frame's bbox.
                        if previous_bbox is not None and next_bbox is not None:
                            prev_next_overlap = get_intersect(previous_bbox, next_bbox)
                            prev_this_overlap = get_intersect(previous_bbox, bbox)
                            this_next_overlap = get_intersect(bbox, next_bbox)
                            if prev_next_overlap is not None and prev_this_overlap is not None and this_next_overlap is not None:
                                if prev_next_overlap[0] > prev_this_overlap[0] and prev_next_overlap[0] > this_next_overlap[0]:
                                    this_bbox = prev_next_overlap[1]
                                else:
                                    this_bbox = bbox
                            else:
                                this_bbox = bbox
                        # If we only have the current and previous or current and next bounding boxes,
                        # check that their overlap area is within some threshold of their mean areas
                        elif previous_bbox is not None:
                            prev_this_overlap = get_intersect(previous_bbox, bbox)
                            this_area = get_bbox_area(bbox)
                            prev_area = get_bbox_area(previous_bbox)
                            if prev_this_overlap is not None and (prev_this_overlap[0] / ((this_area + prev_area)/2) > overlap_threshold):
                                this_bbox = prev_this_overlap[1]
                            else:
                                this_bbox = bbox
                        elif next_bbox is not None:
                            this_next_overlap = get_intersect(bbox, next_bbox)
                            this_area = get_bbox_area(bbox)
                            next_area = get_bbox_area(next_bbox)
                            if this_next_overlap is not None and (this_next_overlap[0] / ((this_area + next_area)/2) > overlap_threshold):
                                this_bbox = this_next_overlap[1]
                            else:
                                this_bbox = bbox

                        if in_bbox_check(this_coord, this_bbox):
                            new_coords[j] = this_coord
                        else:
                            if try_extrapolated_position and j in corrected_coords and in_bbox_check(corrected_coords[j], this_bbox):
                                this_coord = corrected_coords[j]
                            else:
                                this_coord = np.array([(bbox['xmax'] + bbox['xmin'])/2, (bbox['ymax'] + bbox['ymin'])/2, D_THRESH])
                                new_coords[j] = this_coord

                frame_series[i]['figures'][f].data = new_coords

        if flip_figures:
            frame_series[i]['flipped_figures'] = flip_detections(frame_series[i]['figures'])
            frame_series[i]['rectified_figures'] = flip_detections(frame_series[i]['figures'], rectify_x=True)
        else:
            frame_series[i]['flipped_figures'] = frame_series[i]['figures']
            frame_series[i]['rectified_figures'] = flip_detections(frame_series[i]['figures'], flip_y=False, rectify_x=True)

        frame_series[i]['zeroified_figures'] = zeroify_detections(frame_series[i]['figures'])

    return frame_series


def output_alphapose_json(poses_series, figure_type='figures'):
    ap_data = []
    image_count = 0
    for frame in poses_series:
        image_count += 1
        image_id = "image" + str(image_count).zfill(5) + '.png'
        #ap_data[image_id] = []
        for p, pose in enumerate(frame[figure_type]):
            score = float(pose.score() * 10)
            rect_pose = frame[figure_type][p]
            keypoints = []
            for kp in pose.data:
                keypoints.extend([float(kp[0]),float(kp[1]),float(kp[2])])
            #ap_data[image_id].append({'score': score, 'keypoints': keypoints})
            ap_data.append({'image_id': image_id, 'score': score, 'keypoints': keypoints})

    with open("alphapose_output.json", 'w') as jfile:
        json.dump(ap_data, jfile)

#!python2 AlphaPose/PoseFlow/tracker-general.py --in_json alphapose_output.json --out_json alphapose_tracked_output.json --imgdir video_frames/BTS_Fire_Full.mp4/


def add_poseflow_figures(input_detections, json_path):

    poses_series = copy.deepcopy(input_detections)

    with open(json_path, 'r') as jfile:
        pf_data = json.load(jfile)
    i = 0
    # NOTE: The image IDs must be sorted properly (not done in original PoseFlow)
    tracked_poses = 0
    image_ids = []
    print("SORTING IMAGE IDS AND GETTING TOTAL TRACKED FIGURES")
    for image_id in pf_data:
        image_ids.append(image_id)
        for figure in pf_data[image_id]:
            if 'idx' in figure:
                tracked_poses = max(int(figure['idx'])-1,tracked_poses)
    print("TOTAL TRACKED POSES",tracked_poses+1)
    #for image_id in pf_data:
    for image_id in sorted(image_ids):
        poses_series[i]['aligned_figures'] = []
        aligned_figures = {}
        for figure in pf_data[image_id]:
            if 'idx' not in figure:
                continue
            idx = figure['idx']
            aligned_figures[int(idx)-1] = figure
        for p in range(0,tracked_poses):
            if p in aligned_figures:
                figure = aligned_figures[p]
                score = figure['scores']
                keypoints = figure['keypoints']
                aligned_keypoints = []
                print("Adding keypoints for figure number",p,"ID is",figure['idx'])
                for k in range(0,len(keypoints),3):
                    aligned_keypoints.append([keypoints[k], keypoints[k+1], keypoints[k+2]])
            else:
                aligned_keypoints = []
            this_annotation = openpifpaf.Annotation(keypoints=COCO_KEYPOINTS, skeleton=COCO_PERSON_SKELETON).set(np.asarray(aligned_keypoints), fixed_score=None)
            poses_series[i]['aligned_figures'].append(this_annotation)
            if aligned_keypoints:
                poses_series[i]['aligned_figures'][poses_series[i]['aligned_figures'].index(this_annotation)].text = str(figure['idx'])

    # Poses are usually already flipped by this point. If not, the code below would work.
    #if 'flipped_figures' in poses_series[i]:
    #  poses_series[i]['flipped_figures'][f] = flip_detections(poses_series[i]['aligned_figures'])